{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A python stream generating application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exit(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zby0902/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/zby0902/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-1-5ffcb472e905>\", line 62, in generate_stream\n",
      "    conn.close()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import socket\n",
    "from multiprocessing import Process\n",
    "import random, string\n",
    "import json\n",
    "\n",
    "\n",
    "with open('./ClimateData-Part2.csv','r') as c2, open ('./FireData-Part2.csv','r') as f2:\n",
    "    climate_reader = csv.reader(c2)\n",
    "    fire_reader  = csv.reader(f2)\n",
    "    climate = []\n",
    "    fire  = []\n",
    "    for row in climate_reader:\n",
    "        climate.append(row)\n",
    "    for line in fire_reader:\n",
    "        line.append(''.join(random.choices(string.ascii_letters + string.digits, k=12)))\n",
    "        fire.append(line)\n",
    "climate =  climate[1:]\n",
    "fire = fire[1:]  \n",
    "def generator():\n",
    "    for i in range(534):\n",
    "        try:\n",
    "            yield [climate[i],fire[5*i:5*i+5]]\n",
    "        except IndexError:\n",
    "            yield fire[5*i:5*i+5]\n",
    "            \n",
    "            \n",
    "generator = generator()\n",
    "\n",
    "\n",
    "def generate_stream(dataset,port):\n",
    "    \"\"\"\n",
    "    The method that generate a stream sending to socket of the computer from a given dataset\n",
    "    -------\n",
    "    Parameters:\n",
    "    dataset ---the generator object of the dataset\n",
    "    port --- the usable port that the data stream can be sent through\n",
    "    \"\"\" \n",
    "    host = 'localhost'\n",
    "\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "\n",
    "    s.bind((host, port))\n",
    "    s.listen(1)\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            conn, addr = s.accept()\n",
    "            print(\"exit({})\".format(i))\n",
    "            i += 1\n",
    "            while True:\n",
    "                try:\n",
    "                    string = json.dumps(next(dataset))\n",
    "                    conn.send(string.encode())\n",
    "                    time.sleep(1)\n",
    "                except StopIteration:\n",
    "                    return\n",
    "        except socket.error: \n",
    "            pass\n",
    "        finally:\n",
    "            conn.close()\n",
    "            s.close()\n",
    "    conn.close()\n",
    "    s.close()\n",
    "    return\n",
    "if __name__ == '__main__':\n",
    "    #here we must open the two sockets using mp so that it will be openn at the same time\n",
    "    #otherwise the other port cannot be connected to pyspark DStream\n",
    "    p = Process(target=generate_stream, args=(generator,9999))\n",
    "    p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "j_str = json.dumps(next(generator))\n",
    "b = j_str.encode()\n",
    "d = b.decode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "back = json.loads(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cdata',\n",
       "  '948700',\n",
       "  '17',\n",
       "  '52.5',\n",
       "  '6.7',\n",
       "  '12',\n",
       "  '   69.6*',\n",
       "  '  52.7*',\n",
       "  ' 0.00G'],\n",
       " [['fdata', '-36.94', '143.281', '342.2', '36.8', '89', '69', 'a20rXKHJqAxv'],\n",
       "  ['fdata', '-36.943', '143.286', '302.7', '18.8', '51', '29', 'WTMAzbxyOVaY'],\n",
       "  ['fdata', '-36.941', '143.268', '310.5', '11.6', '80', '37', 'ZQmKyx1JXP2m'],\n",
       "  ['fdata', '-36.939', '143.28', '332.4', '36.7', '100', '59', 'DZjFJKPQxAME'],\n",
       "  ['fdata', '-37.863', '144.17', '333.8', '46.5', '86', '60', 'p6YWoGuPOukD']]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate =  climate[1:]\n",
    "fire = fire[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ClimateData-Part2.csv','r') as c2, open ('./FireData-Part2.csv','r') as f2:\n",
    "    climate_reader = csv.reader(c2)\n",
    "    fire_reader  = csv.reader(f2)\n",
    "    climate = []\n",
    "    fire  = []\n",
    "    for row in climate_reader:\n",
    "        climate.append(','.join(e.strip() for e in row) + '\\n ')\n",
    "    for line in fire_reader:\n",
    "        line.append(uuid.uuid1().hex)\n",
    "        fire.append(','.join(e.strip() for e in line) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366, 534)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(climate),len(fire)//5 +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(dataset):\n",
    "    for e in dataset:\n",
    "        yield e\n",
    "c = generator(climate)\n",
    "f = generator(fire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fire)//5 +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### another question is that, everything send through socket is byte, is it possible that we reverse it back to list and retain its original information?\n",
    "- String willbe the easiest to encode and decode\n",
    "#### If we save each record just in a string sperated by \",\", then the encode and decode will be much easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to json str\n",
    "t = json.dumps(next(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json str to byte and back to json str\n",
    "t = t.encode()\n",
    "t.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json str back to list\n",
    "json.loads(t)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_streams():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netcat('localhost',9999,'aa aa aa aaaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a():\n",
    "    for e in range(3):\n",
    "        yield e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g =a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        print(next(g))\n",
    "    except StopIteration:\n",
    "        print('done')\n",
    "        break\n",
    "    finally:\n",
    "        print('yes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we need to create two socket connection for the two datasets to generate two streams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

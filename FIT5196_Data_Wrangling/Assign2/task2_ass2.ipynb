{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Task 2 in Assessment 2\n",
    "#### Student Name: Boyu Zhang\n",
    "#### Student ID: 28491300\n",
    "\n",
    "Date: XX/XX/XXXX\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3.6 and Jupyter notebook\n",
    "\n",
    "Libraries used: please include the main libraries you used in your assignment here, e.g.,:\n",
    "* pandas (for dataframe, included in Anaconda Python ) \n",
    "* re (for regular expression, included in Anaconda Python 3.6) \n",
    "* numpy (for numpy array, included in Anaconda Python 3.6)\n",
    "* jellyfish (for vairous string similarity matching, obtained by `pip install jellyfish`)\n",
    "* sklearn (as depency of recordlinkag, obtained by `conda install scikit-learn`)\n",
    "* recordlinkage (for record matching operations, obatained by `pip install recordlinkage`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to import libraries as you need in this assessment, e.g.,\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import jellyfish\n",
    "import recordlinkage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load datasets and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('./Input/dataset2_integration.csv')\n",
    "df1 = pd.read_csv('./dataset1_solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Title', 'Location', 'ContractType', 'ContractTime', 'Company',\n",
       "       'Category', 'Salary per annum', 'SourceName', 'OpenDate', 'CloseDate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Source Name', 'Title', 'location', 'Contract Type',\n",
       "       'Contract Time', 'Company', 'Category', 'Salary per month', 'OpenDate',\n",
       "       'CloseDate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there are two schema level conflicst between the two datasets:\n",
    "1. There are attributes with same semantics that are not aligned\n",
    "2. The `Salary` column is inconsistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Integrate Datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Resolve schema conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we realign the order of columns in dataset2 and change the unit of `Salary` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unify unit of salary and re-align columns by adjusting schema of dataset2\n",
    "new_salary = df2['Salary per month'].astype(int)*12\n",
    "df2.drop(columns='Salary per month',inplace=True)\n",
    "df2.insert(loc=8,column='Salary per annum',value=new_salary)\n",
    "source = df2['Source Name'] \n",
    "df2.drop(columns='Source Name',inplace=True)\n",
    "df2.insert(loc=8,column='SourceName',value=source)\n",
    "df2.rename(columns={'location':'Location','Contract Type':'ContractType','Contract Time':'ContractTime'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final check before concatenating two datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>Salary per annum</th>\n",
       "      <th>SourceName</th>\n",
       "      <th>OpenDate</th>\n",
       "      <th>CloseDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>non_specified</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>24996</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>2012-11-03 00:00:00</td>\n",
       "      <td>2012-12-03 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>non_specified</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>2013-01-08 15:00:00</td>\n",
       "      <td>2013-04-08 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling And Simulation Analyst</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>non_specified</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>2013-07-26 15:00:00</td>\n",
       "      <td>2013-09-24 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>non_specified</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>27504</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>2012-12-14 00:00:00</td>\n",
       "      <td>2013-03-14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>non_specified</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>24996</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>2013-10-25 00:00:00</td>\n",
       "      <td>2013-12-24 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title   Location  \\\n",
       "0  12612628                        Engineering Systems Analyst    Dorking   \n",
       "1  12612830                            Stress Engineer Glasgow    Glasgow   \n",
       "2  12612844                   Modelling And Simulation Analyst  Hampshire   \n",
       "3  12613049  Engineering Systems Analyst / Mathematical Mod...     Surrey   \n",
       "4  12613647         Pioneer, Miser Engineering Systems Analyst     Surrey   \n",
       "\n",
       "    ContractType ContractTime                       Company          Category  \\\n",
       "0  non_specified    permanent  Gregory Martin International  Engineering Jobs   \n",
       "1  non_specified    permanent  Gregory Martin International  Engineering Jobs   \n",
       "2  non_specified    permanent  Gregory Martin International  Engineering Jobs   \n",
       "3  non_specified    permanent  Gregory Martin International  Engineering Jobs   \n",
       "4  non_specified    permanent  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "   Salary per annum        SourceName             OpenDate  \\\n",
       "0             24996  cv-library.co.uk  2012-11-03 00:00:00   \n",
       "1             30000  cv-library.co.uk  2013-01-08 15:00:00   \n",
       "2             30000  cv-library.co.uk  2013-07-26 15:00:00   \n",
       "3             27504  cv-library.co.uk  2012-12-14 00:00:00   \n",
       "4             24996  cv-library.co.uk  2013-10-25 00:00:00   \n",
       "\n",
       "             CloseDate  \n",
       "0  2012-12-03 00:00:00  \n",
       "1  2013-04-08 15:00:00  \n",
       "2  2013-09-24 15:00:00  \n",
       "3  2013-03-14 00:00:00  \n",
       "4  2013-12-24 00:00:00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>Salary per annum</th>\n",
       "      <th>SourceName</th>\n",
       "      <th>OpenDate</th>\n",
       "      <th>CloseDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69247680</td>\n",
       "      <td>Business Development Exec  research / insight ...</td>\n",
       "      <td>London</td>\n",
       "      <td>ft</td>\n",
       "      <td>perm.</td>\n",
       "      <td>BOYCE RECRUITMENT</td>\n",
       "      <td>PR, Advertising &amp; Marketing Jobs</td>\n",
       "      <td>25500</td>\n",
       "      <td>jobs.guardian.co.uk</td>\n",
       "      <td>2012-03-01 15:00:00</td>\n",
       "      <td>2012-03-31 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69247682</td>\n",
       "      <td>Audit Senior  London</td>\n",
       "      <td>London</td>\n",
       "      <td>ft</td>\n",
       "      <td>contr.</td>\n",
       "      <td>Pro Finance</td>\n",
       "      <td>Finance &amp; Accounting Jobs</td>\n",
       "      <td>43200</td>\n",
       "      <td>icaewjobs.com</td>\n",
       "      <td>2013-03-14 12:00:00</td>\n",
       "      <td>2013-04-13 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69247685</td>\n",
       "      <td>PR &amp; Social Media Account Executive  Top Inter...</td>\n",
       "      <td>Central London</td>\n",
       "      <td>ft</td>\n",
       "      <td>perm.</td>\n",
       "      <td>ECOM RECRUITMENT LTD</td>\n",
       "      <td>PR, Advertising &amp; Marketing Jobs</td>\n",
       "      <td>23004</td>\n",
       "      <td>jobs.guardian.co.uk</td>\n",
       "      <td>2012-02-14 12:00:00</td>\n",
       "      <td>2012-03-15 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69247688</td>\n",
       "      <td>Content Manager</td>\n",
       "      <td>London</td>\n",
       "      <td>ft</td>\n",
       "      <td>perm.</td>\n",
       "      <td>NAKAMA LONDON</td>\n",
       "      <td>PR, Advertising &amp; Marketing Jobs</td>\n",
       "      <td>24996</td>\n",
       "      <td>jobs.guardian.co.uk</td>\n",
       "      <td>2012-10-21 00:00:00</td>\n",
       "      <td>2012-12-20 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69247694</td>\n",
       "      <td>AV PRODUCTION MANAGER</td>\n",
       "      <td>Worcestershire</td>\n",
       "      <td>ft</td>\n",
       "      <td>perm.</td>\n",
       "      <td>LIVE RECRUITMENT</td>\n",
       "      <td>PR, Advertising &amp; Marketing Jobs</td>\n",
       "      <td>27504</td>\n",
       "      <td>jobs.guardian.co.uk</td>\n",
       "      <td>2012-02-22 00:00:00</td>\n",
       "      <td>2012-04-22 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  69247680  Business Development Exec  research / insight ...   \n",
       "1  69247682                               Audit Senior  London   \n",
       "2  69247685  PR & Social Media Account Executive  Top Inter...   \n",
       "3  69247688                                    Content Manager   \n",
       "4  69247694                              AV PRODUCTION MANAGER   \n",
       "\n",
       "         Location ContractType ContractTime               Company  \\\n",
       "0          London           ft        perm.     BOYCE RECRUITMENT   \n",
       "1          London           ft       contr.           Pro Finance   \n",
       "2  Central London           ft        perm.  ECOM RECRUITMENT LTD   \n",
       "3          London           ft        perm.         NAKAMA LONDON   \n",
       "4  Worcestershire           ft        perm.      LIVE RECRUITMENT   \n",
       "\n",
       "                           Category  Salary per annum           SourceName  \\\n",
       "0  PR, Advertising & Marketing Jobs             25500  jobs.guardian.co.uk   \n",
       "1         Finance & Accounting Jobs             43200        icaewjobs.com   \n",
       "2  PR, Advertising & Marketing Jobs             23004  jobs.guardian.co.uk   \n",
       "3  PR, Advertising & Marketing Jobs             24996  jobs.guardian.co.uk   \n",
       "4  PR, Advertising & Marketing Jobs             27504  jobs.guardian.co.uk   \n",
       "\n",
       "              OpenDate            CloseDate  \n",
       "0  2012-03-01 15:00:00  2012-03-31 15:00:00  \n",
       "1  2013-03-14 12:00:00  2013-04-13 12:00:00  \n",
       "2  2012-02-14 12:00:00  2012-03-15 12:00:00  \n",
       "3  2012-10-21 00:00:00  2012-12-20 00:00:00  \n",
       "4  2012-02-22 00:00:00  2012-04-22 00:00:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Resolve data conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inconsistence\n",
    "It seems there are still inconsisent representation of same values in `ContractType` and `ContractTime` columns, as well as inconsistent caplital letters in `Company` column, we fix them now before checking duplication.\n",
    "\n",
    "Otherwise it may be incorrectly regarded as different strings which will harm the accuracy of duplicates-dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.ContractType = df2.ContractType.map({'ft':'full_time','pt':'part_time',np.nan:'non_specified'})\n",
    "df2.ContractTime = df2.ContractTime.map({'perm.':'permanent','contr.':'contract',np.nan:'non_specified'})\n",
    "df2.Company = df2.Company.str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplication\n",
    "- We should figure out a global key -- a set of features to identify whether two records are duplicated or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.set_index('Id',inplace=True)\n",
    "df2.set_index('Id',inplace=True)\n",
    "df1.index.rename('Id1',inplace=True)\n",
    "df2.index.rename('Id2',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we should consider comparing similarity of records based on a set of features:\n",
    "- We should pick out some features that we regard as identical for each record\n",
    "- From the previous observation we can see that the `Title` of each record is unlikely to be highly similar to others, almost everything from \"Year number\" to \"London\" and \"20K\" can be included in.\n",
    "- Also the precision of `Salary` is to the last digit, thus they shall be identical to certain extent as well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to confirm our inference based on statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25077 Title\n",
      "477 Location\n",
      "3 ContractType\n",
      "3 ContractTime\n",
      "4705 Company\n",
      "8 Category\n",
      "1570 Salary per annum\n",
      "90 SourceName\n",
      "2193 OpenDate\n",
      "2400 CloseDate\n"
     ]
    }
   ],
   "source": [
    "# test uniqueness level of features in df1\n",
    "cols = list(df1.columns)\n",
    "for col in cols:\n",
    "    print(df1[col].unique().shape[0],col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25276 Title\n",
      "475 Location\n",
      "3 ContractType\n",
      "3 ContractTime\n",
      "5546 Company\n",
      "8 Category\n",
      "1505 Salary per annum\n",
      "92 SourceName\n",
      "2193 OpenDate\n",
      "2395 CloseDate\n"
     ]
    }
   ],
   "source": [
    "# test uniqueness level of features in df2\n",
    "cols = list(df2.columns)\n",
    "for col in cols:\n",
    "    print(df2[col].unique().shape[0],col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision\n",
    "So we pick the combination of features with the top level of uniqueness in both datasets:\n",
    "`Title`,`Company`,`Salary per annum`,`OpenDate`,`CloseDate`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One more tip**:\n",
    "\n",
    "It is unsual that \"np.nan == np.nan\" will return **False**, we recall from task1 that there are quite a number of null values in df1 which will harm the performance of our deduplication process.\n",
    "\n",
    "Thus we replace the null value with same string \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Company.fillna('Unknown',inplace=True)\n",
    "df2.Company.fillna('Unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create record pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to check whether there are potential duplicated records in each dataset itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer = recordlinkage.BlockIndex(on=['Title','Company','Salary per annum','OpenDate','CloseDate'])\n",
    "pairs = indexer.index(df1)\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer = recordlinkage.BlockIndex(on=['Title','Company','Salary per annum','OpenDate','CloseDate'])\n",
    "pairs = indexer.index(df2)\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means no potential duplicated records are found respectively in each dataset.\n",
    "\n",
    "Then we need to find potential pairs in both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer = recordlinkage.BlockIndex(on=['Title','Company','Salary per annum','OpenDate','CloseDate'])\n",
    "pairs = indexer.index(df1,df2)\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to compute the simliarity of each record pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_cl = recordlinkage.Compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34364.174741795272"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get mean value of salary to provide reference to salary similarity comparison\n",
    "df1['Salary per annum'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set a few threshold on giving the similarity score, if similarity level exceeds the threshold, we give it 1, otherwise 0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the similarity score of each selected feature between record pairs\n",
    "compare_cl = recordlinkage.Compare()\n",
    "# since the title is too customized we try not be too strict on them\n",
    "compare_cl.string('Title','Title',threshold=0.6,method='levenshtein',label='Title')\n",
    "#Company is not that unique, so we set higher threshold\n",
    "compare_cl.string('Company','Company',threshold=0.8,label='Company')\n",
    "# The salary comparison is based on gaussian distribution, the scale is based on the mean value\n",
    "compare_cl.numeric('Salary per annum','Salary per annum',scale=1000,method='gauss',label='Salary')\n",
    "compare_cl.string('OpenDate','OpenDate',threshold=0.95,label='OpenDate')\n",
    "compare_cl.string('CloseDate','CloseDate',threshold=0.95,label='CloseDate')\n",
    "features = compare_cl.compute(pairs, df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>OpenDate</th>\n",
       "      <th>CloseDate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id1</th>\n",
       "      <th>Id2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44363005</th>\n",
       "      <th>72446581</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46632961</th>\n",
       "      <th>70176593</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46637204</th>\n",
       "      <th>72032810</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50881828</th>\n",
       "      <th>71680650</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60685289</th>\n",
       "      <th>71850757</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62282446</th>\n",
       "      <th>71774964</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64146768</th>\n",
       "      <th>71749988</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64353737</th>\n",
       "      <th>69896092</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65171288</th>\n",
       "      <th>72625397</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65186958</th>\n",
       "      <th>71526512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65197866</th>\n",
       "      <th>71556127</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65864451</th>\n",
       "      <th>70782959</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66014654</th>\n",
       "      <th>69685781</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66190499</th>\n",
       "      <th>70107711</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66574784</th>\n",
       "      <th>70107934</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66584113</th>\n",
       "      <th>71797939</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66600350</th>\n",
       "      <th>72127656</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66600448</th>\n",
       "      <th>70140804</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66700259</th>\n",
       "      <th>71294434</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66789993</th>\n",
       "      <th>69693243</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66887305</th>\n",
       "      <th>70255629</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66936459</th>\n",
       "      <th>72441982</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66946907</th>\n",
       "      <th>69556650</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67366446</th>\n",
       "      <th>71593885</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67652681</th>\n",
       "      <th>71352754</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67779540</th>\n",
       "      <th>71476106</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67786940</th>\n",
       "      <th>70770400</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67894665</th>\n",
       "      <th>72184151</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67953363</th>\n",
       "      <th>71685337</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68057640</th>\n",
       "      <th>71805087</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68637468</th>\n",
       "      <th>69249686</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68663523</th>\n",
       "      <th>71677827</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68672601</th>\n",
       "      <th>69596503</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68676551</th>\n",
       "      <th>69638838</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68677673</th>\n",
       "      <th>71659641</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68677674</th>\n",
       "      <th>71677008</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68681886</th>\n",
       "      <th>71336037</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68682135</th>\n",
       "      <th>70760908</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68683745</th>\n",
       "      <th>71878731</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68684201</th>\n",
       "      <th>69933462</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68689938</th>\n",
       "      <th>71677134</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68699696</th>\n",
       "      <th>69570901</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68703340</th>\n",
       "      <th>71564645</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68710969</th>\n",
       "      <th>71233385</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68791552</th>\n",
       "      <th>70090756</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68814716</th>\n",
       "      <th>72344120</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68823907</th>\n",
       "      <th>72186969</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68834653</th>\n",
       "      <th>71240889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68838100</th>\n",
       "      <th>71625551</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68994391</th>\n",
       "      <th>70016388</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69007567</th>\n",
       "      <th>71907207</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69011830</th>\n",
       "      <th>69250133</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69012230</th>\n",
       "      <th>71198448</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69019109</th>\n",
       "      <th>71844022</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69023153</th>\n",
       "      <th>69816417</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69055093</th>\n",
       "      <th>70757696</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69079178</th>\n",
       "      <th>71565465</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69083303</th>\n",
       "      <th>71680355</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69172167</th>\n",
       "      <th>71911500</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69173554</th>\n",
       "      <th>70677754</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Title  Company  Salary  OpenDate  CloseDate\n",
       "Id1      Id2                                                  \n",
       "44363005 72446581    1.0      1.0     1.0       1.0        1.0\n",
       "46632961 70176593    1.0      1.0     1.0       1.0        1.0\n",
       "46637204 72032810    1.0      1.0     1.0       1.0        1.0\n",
       "50881828 71680650    1.0      1.0     1.0       1.0        1.0\n",
       "60685289 71850757    1.0      1.0     1.0       1.0        1.0\n",
       "62282446 71774964    1.0      1.0     1.0       1.0        1.0\n",
       "64146768 71749988    1.0      1.0     1.0       1.0        1.0\n",
       "64353737 69896092    1.0      1.0     1.0       1.0        1.0\n",
       "65171288 72625397    1.0      1.0     1.0       1.0        1.0\n",
       "65186958 71526512    1.0      1.0     1.0       1.0        1.0\n",
       "65197866 71556127    1.0      1.0     1.0       1.0        1.0\n",
       "65864451 70782959    1.0      1.0     1.0       1.0        1.0\n",
       "66014654 69685781    1.0      1.0     1.0       1.0        1.0\n",
       "66190499 70107711    1.0      1.0     1.0       1.0        1.0\n",
       "66574784 70107934    1.0      1.0     1.0       1.0        1.0\n",
       "66584113 71797939    1.0      1.0     1.0       1.0        1.0\n",
       "66600350 72127656    1.0      1.0     1.0       1.0        1.0\n",
       "66600448 70140804    1.0      1.0     1.0       1.0        1.0\n",
       "66700259 71294434    1.0      1.0     1.0       1.0        1.0\n",
       "66789993 69693243    1.0      1.0     1.0       1.0        1.0\n",
       "66887305 70255629    1.0      1.0     1.0       1.0        1.0\n",
       "66936459 72441982    1.0      1.0     1.0       1.0        1.0\n",
       "66946907 69556650    1.0      1.0     1.0       1.0        1.0\n",
       "67366446 71593885    1.0      1.0     1.0       1.0        1.0\n",
       "67652681 71352754    1.0      1.0     1.0       1.0        1.0\n",
       "67779540 71476106    1.0      1.0     1.0       1.0        1.0\n",
       "67786940 70770400    1.0      1.0     1.0       1.0        1.0\n",
       "67894665 72184151    1.0      1.0     1.0       1.0        1.0\n",
       "67953363 71685337    1.0      1.0     1.0       1.0        1.0\n",
       "68057640 71805087    1.0      1.0     1.0       1.0        1.0\n",
       "...                  ...      ...     ...       ...        ...\n",
       "68637468 69249686    1.0      1.0     1.0       1.0        1.0\n",
       "68663523 71677827    1.0      1.0     1.0       1.0        1.0\n",
       "68672601 69596503    1.0      1.0     1.0       1.0        1.0\n",
       "68676551 69638838    1.0      1.0     1.0       1.0        1.0\n",
       "68677673 71659641    1.0      1.0     1.0       1.0        1.0\n",
       "68677674 71677008    1.0      1.0     1.0       1.0        1.0\n",
       "68681886 71336037    1.0      1.0     1.0       1.0        1.0\n",
       "68682135 70760908    1.0      1.0     1.0       1.0        1.0\n",
       "68683745 71878731    1.0      1.0     1.0       1.0        1.0\n",
       "68684201 69933462    1.0      1.0     1.0       1.0        1.0\n",
       "68689938 71677134    1.0      1.0     1.0       1.0        1.0\n",
       "68699696 69570901    1.0      1.0     1.0       1.0        1.0\n",
       "68703340 71564645    1.0      1.0     1.0       1.0        1.0\n",
       "68710969 71233385    1.0      1.0     1.0       1.0        1.0\n",
       "68791552 70090756    1.0      1.0     1.0       1.0        1.0\n",
       "68814716 72344120    1.0      1.0     1.0       1.0        1.0\n",
       "68823907 72186969    1.0      1.0     1.0       1.0        1.0\n",
       "68834653 71240889    1.0      1.0     1.0       1.0        1.0\n",
       "68838100 71625551    1.0      1.0     1.0       1.0        1.0\n",
       "68994391 70016388    1.0      1.0     1.0       1.0        1.0\n",
       "69007567 71907207    1.0      1.0     1.0       1.0        1.0\n",
       "69011830 69250133    1.0      1.0     1.0       1.0        1.0\n",
       "69012230 71198448    1.0      1.0     1.0       1.0        1.0\n",
       "69019109 71844022    1.0      1.0     1.0       1.0        1.0\n",
       "69023153 69816417    1.0      1.0     1.0       1.0        1.0\n",
       "69055093 70757696    1.0      1.0     1.0       1.0        1.0\n",
       "69079178 71565465    1.0      1.0     1.0       1.0        1.0\n",
       "69083303 71680355    1.0      1.0     1.0       1.0        1.0\n",
       "69172167 71911500    1.0      1.0     1.0       1.0        1.0\n",
       "69173554 70677754    1.0      1.0     1.0       1.0        1.0\n",
       "\n",
       "[86 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for all 5 features we regard two record with score higher than 4 as duplicated\n",
    "matches = features[features.sum(axis=1) > 4]\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick check does the pair looks really close to each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title               Clinical Project Manager (Late Phase)  Germany\n",
       "Location                                                        UK\n",
       "ContractType                                             full_time\n",
       "ContractTime                                             permanent\n",
       "Company                                           Barrington James\n",
       "Category                                 Healthcare & Nursing Jobs\n",
       "Salary per annum                                             60000\n",
       "SourceName                                       strike-jobs.co.uk\n",
       "OpenDate                                       2012-01-02 12:00:00\n",
       "CloseDate                                      2012-02-01 12:00:00\n",
       "Name: 68838100, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[68838100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title               Clinical Project Manager (Late Phase)  Germany\n",
       "Location                                                        UK\n",
       "ContractType                                             full_time\n",
       "ContractTime                                             permanent\n",
       "Company                                           Barrington James\n",
       "Category                                 Healthcare & Nursing Jobs\n",
       "Salary per annum                                             60000\n",
       "SourceName                                       strike-jobs.co.uk\n",
       "OpenDate                                       2012-01-02 12:00:00\n",
       "CloseDate                                      2012-02-01 12:00:00\n",
       "Name: 71625551, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[71625551]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems the result is not bad, so we can now regard these 73 records as duplicated so we can drop them in either dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the list of ids for records to delete in df1(either way is valid)\n",
    "id_to_delete = list(features.index.get_level_values('Id1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the duplicated rows in dataset1\n",
    "df1 = df1.drop(index=id_to_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last check of no duplicated records detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#last check of potential duplicated record pairs\n",
    "pairs = indexer.index(df1,df2)\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#undo changes to make dataset looks the same as original\n",
    "df1.reset_index(level=0, inplace=True)\n",
    "df2.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine 2 datasets\n",
    "df = pd.concat((df1,df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# third check of no duplication existing after the merge of datasets\n",
    "df.duplicated(['Title','Company','Salary per annum','OpenDate','CloseDate']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no more duplicates, we can output the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output\n",
    "df.to_csv('./dataset1_dataset2_solution.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary\n",
    "There are various way(algorithms) of measure similarity of strings and numeric values, we need to make a lot of choices. Thus the result can be quite dependent on the measures and features we pick.\n",
    "### Reference\n",
    " 1. recordlinkage. Retrieved from http://recordlinkage.readthedocs.io/en/latest/notebooks/data_deduplication.html\n",
    " 2. How to get index values pandas.Retrieved from: https://stackoverflow.com/questions/18358938/get-row-index-values-of-pandas-dataframe-as-list\n",
    " 3. How to convert pandas index in a dataframe to a column? Retrieved from:https://stackoverflow.com/questions/20461165/how-to-convert-pandas-index-in-a-dataframe-to-a-column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:5196]",
   "language": "python",
   "name": "conda-env-5196-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
